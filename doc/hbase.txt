http://hbasefly.com/2016/09/26/hbase-mutiltenant-1/    HBase最佳实践－多租户机制简析
http://mp.weixin.qq.com/s?spm=5176.100239.blogcont63134.26.eJ0K6L&__biz=MzAxNjc1MTk5Nw==&mid=400828499&idx=1&sn=c898c6b0ff752ece4e631565aa83a394   HBase高可用原理与实践
https://help.aliyun.com/document_detail/31792.html?spm=5176.789091351.6.137.T5psPM  端口转发 chrome代理
cat ~/.ssh/id_rsa.pub   -->   vim ~/.ssh/authorized_keys
ssh -i ~/.ssh/id_rsa -ND 8157 root@xx.xx.xx.xx
数据处理的大致步骤，数据源->数据清洗->数据存储服务->数据分析->可视化展示(有的没有)
https://yq.aliyun.com/articles/57136?spm=5176.8091938.0.0.iTT3re
https://yq.aliyun.com/articles/54650?spm=5176.8091938.0.0.iTT3re
CarbonData是一个新的存储格式，跟parquet、orcfile比较类似。大致就是在列式存储的基础上加上编码、倒排等index的技术。
https://yq.aliyun.com/articles/53918?spm=5176.8091938.0.0.iTT3re   用户自助搭建Gateway访问E-MapReduce

http://www.ibm.com/developerworks/cn/java/j-lo-HBase/   HBase 数据库检索性能优化策略
http://www.aliog.com/70845.html  HBase性能优化完全版
http://dailidong.blog.51cto.com/4183991/1735157   Hbase万亿级存储性能优化总结
http://jxy.me/2015/07/06/hbase-tips/  HBase豆知识
http://hbase.apache.org/book.html#performance
http://www.chinastor.com/a/hbase/0G3U922014.html   HBase应用性能测试方法
http://www.adintellig.com/hbase-write-tuning/     HBase写入性能调优
http://www.adintellig.com/apache-hbase-1-0-0-release/   hbase 1.0
https://github.com/ndimiduk/hbase-1.0-api-examples/tree/master/src/main/java/com/n10k
https://github.com/apache/hbase/blob/master/src/main/asciidoc/_chapters/upgrading.adoc
zookeeper-3.4.3/bin/zkCleanup.sh <DataDir> <Count>  备注：其中DataDir指的是配置文件中的日志文件及快照文件存放的路径地址；Count指的是要保留最近的数据份数。
http://xstarcd.github.io/wiki/Cloud/zookeeper_log_snapshot.html  从3.4.0开始，zookeeper提供了自动清理snapshot和事务日志的功能，通过配置 autopurge.snapRetainCount 和 autopurge.purgeInterval 这两个参数能够实现定时清理了。这两个参数都是在zoo.cfg中配置的
http://xstarcd.github.io/wiki/Cloud/hbase_tips.html   hbase日常操作收集
可以从 zookeeper 上面获取到所有的在线 RegionServer       zkCli.sh ls /hbase/rs
然后就是在中控机遍历这些机器，挨个进行 graceful 重启     hbase/bin/graceful_stop.sh --restart --reload --debug $host
https://cloud.google.com/bigtable/docs/hbase-api-changes   谷歌的产品支持hbase api

在Spark中提供了一个JdbcRDD类，该RDD就是读取JDBC中的数据并转换成RDD
https://github.com/nerdammer/spark-hbase-connector?spm=5176.docemr/best-practice/HBase.2.5.Wscg3b   spark连接hbase
https://yq.aliyun.com/articles/25702?spm=5176.blog25477.yqblogcon1.22.nzl84e  HBase中的一些注意事项
https://yq.aliyun.com/articles/25477?spm=5176.blog26250.yqblogcon1.25.S9Ifnz   HBase性能调优
https://yq.aliyun.com/articles/26333?spm=0.0.0.0.MqH4b1   远程调试Hadoop各组件
https://github.com/javachen/learning-hadoop
HBase提供了几个特别的原子操作接口 checkAndPut/checkAndDelete/increment/append，这几个接口非常有用，内部实现也是基于行锁
https://github.com/larsgeorge/hbase-book
https://yq.aliyun.com/articles/46936?spm=5176.100239.blogcont.11.uRv01L   hbase七剑
但据FB的committer分享，G1 GC比较适合<=31GB或者>=100GB的场景，32G～100G的堆大小还是CMS更适合    https://yq.aliyun.com/articles/46936?spm=5176.100239.blogcont.11.uRv01L



HBase的Relication机制，事实上和Mysql的同步机制非常像。HBase的每一个Region Server都会有WAL Log，当Put/Delete时。都会先写入到WAL Log里。
然后后台有线程会把WAL Log随机发给Slave的Region Server。而Slave的Region Server会在zookeeper上记录自己同步到的位置。
 
当region在进行compact或者split会出现短暂的读写堵塞。如果Row-Key的区分度不高，性能也不行。
https://www.mapr.com/blog/in-depth-look-hbase-architecture
hbase返回的结果按照rowkey,CF,qualifiers,timestamp的次序进行排序  HBase在进行数据存储时，新数据不会直接覆盖旧的数据，而是进行追加操作，不同的数据通过时间戳进行区分.默认每行数据存储三个版本.
hbase org.apache.hadoop.hbase.util.RegionSplitter test_table HexStringSplit -c 10 -f f1

 ./bin/hbase org.apache.hadoop.hbase.regionserver.CompactionTool
Hbase系统自身提供了性能测试工具：./bin/hbase  org.apache.hadoop.hbase.PerformanceEvaluation，该工具提供了随机读写、多客户端读写等性能测试功能。
hbase org.apache.hadoop.hbase.PerformanceEvaluation randomWrite 1
hbase org.apache.hadoop.hbase.PerformanceEvaluation randomRead 1


https://yq.aliyun.com/articles/37656?spm=5176.blog30549.yqblogcon1.15.kmRPDT&do=login  如何访问E-MapReduce中HBase集群
其实，Phoenix只是一个中间件（或是一个HBase的SQL插件），它的使用较为简单， 将Phoenix目录下的phoenix-*.jar拷贝到HBase的lib目录，这里面是将所有的插件均拷贝到HBase了，若是只使用个别插件，大家可按需选择即可。然后重启HBase集群即可。  https://yq.aliyun.com/articles/34104?spm=5176.blog37656.yqblogcon1.25.z6AEui
Sqoop是一款开源的软件工具，提供了Hadoop和关系型数据库中的数据相互转移的功能。可以将一个关系型数据库（例如 ： MySQL）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。  https://yq.aliyun.com/articles/38620?spm=5176.group78.0.0.M93kBw
https://help.aliyun.com/document_detail/emr/best-practice/DataTransfer/Sqoop.html?spm=5176.blog38620.yqblogcon1.6.7AlYNM
https://yq.aliyun.com/articles/37915?spm=5176.group78.0.0.M93kBw   在RDS上创建Hive元数据仓
E-MapReduce将会很快支持Hue和Zepplin，到时候就可以进行交互式使用Hive和Spark了。

http://blog.csdn.net/u011491148/article/details/45749807    利用Phoenix为HBase创建二级索引
其核心思想是保证索引表和主表在同一个region server上。详见：https://github.com/Huawei-Hadoop/hindex    http://www.dengchuanhua.com/167.html   http://www.thebigdata.cn/upload/2013-10/13101415173453.pdf
HBase在0.92之后引入了coprocessors，提供了一系列的钩子，让我们能够轻易实现访问控制和二级索引的特性。   http://www.dengchuanhua.com/149.html  
在分布式系统中，需要生成全局UID的场合还是比较多的，twitter的snowflake解决了这种需求，实现也还是很简单的，除去配置信息，核心代码就是毫秒级时间41位+机器ID 10位+毫秒内序列12位。
该项目地址为：https://github.com/twitter/snowflake是用Scala实现的。     http://www.dengchuanhua.com/132.html
 
http://my.oschina.net/leejun2005/blog/543048?fromerr=4jqPCSkc  HBase 原理、设计与优化实践
http://www.bitstech.net/2015/12/04/hbase-optmization/?utm_source=tuicool&utm_medium=referral  HBase优化实战
比较像MongoDB的sharding模式，能根据键值的大小，把数据分布到不同的存储节点上，MongoDB根据configserver来定位数据落在哪个分区上，HBase通过访问Zookeeper来获取-ROOT-表所在地址，通过-ROOT-表得到相应.META.表信息，从而获取数据存储的region位置。
http://my.oschina.net/leejun2005/blog/92776  HBase性能优化方法总结
http://navigating.github.io/2015/%E5%AD%A6%E4%B9%A0%E3%80%8AHadoop%E7%94%9F%E6%80%81%E6%8A%80%E6%9C%AF%E5%9C%A8%E9%98%BF%E9%87%8C%E5%85%A8%E7%BD%91%E5%95%86%E5%93%81%E6%90%9C%E7%B4%A2%E5%AE%9E%E6%88%98%E3%80%8B/     Hadoop生态技术在阿里全网商品搜索实战
 
hbase集群复制 ， 多master ha ， incr计数器 ， coprocessor      mysql 单表一般500w，能使用mysql的场景
Trafodion是HP公司资助的一个开源项目。它提供了一个成熟的企业级SQL on HBase解决方案。
HDFS是大数据时代文件系统的事实标准的话，Parquet就是大数据时代存储格式的事实标准。
Phoenix缺乏Join能力，eBay提出的kylin还不够简洁，facebook Presto的HBase连接器还没公开。
http://tephra.io/   Tephra™ provides globally-consistent transactions on top of Apache HBase. 
https://github.com/Huawei-Spark/Spark-SQL-on-HBase   
https://github.com/cloudera-labs/SparkOnHBase   http://navigating.github.io/2015/SparkOnHBase-Cloudera/
https://github.com/NGDATA/hbase-indexer/tree/master/hbase-sep
http://www.oschina.net/news/69616/review-and-development-of-apache-hbase     Apache HBase 2015 年发展回顾与未来展望
https://github.com/yahoo/omid    Omid 项目来自 Yahoo，用于给使用快照隔离的键值存储提供事务支持。    http://tephra.io/
https://github.com/HuaweiBigData/astro    Spark SQL on HBase package 项目又名 Astro，端到端整合了 Spark，Spark SQL和HBase的能力

数据存储格式Parquet和ORCfile,分别是impala和Hive推荐使用的数据格式

YCSB的全称是Yahoo! Cloud Serving Benchmark，这是一个用于测试cloud serving/NoSQL/Key-Value Store的benchmark 
http://support.huawei.com/ecommunity/bbs/10242857.html
https://github.com/brianfrankcooper/YCSB


http://developer.huawei.com/cn/ict/Products/BigData/FusionInsightHD/HBase/SDK#section-4-12    华为hbase
HBase 1.0 建议不要使用org.apache.hadoop.hbase.mapred, 建议使用org.apache.hadoop.hbase.mapreduce
http://www.csdn.net/article/2014-01-15/2818147-hbase-in-2013   回顾2013：HBase的提升与挑战
http://www.tuicool.com/articles/EvaqEb   HBase单机环境搭建
http://ju.outofmemory.cn/entry/234703    hbase standalone模式部署和API测试

http://www.rowkey.me/blog/2015/06/10/hbase-about/
http://songlee24.github.io/2015/07/24/hbase-introduction/

http://www.cnblogs.com/kxdblog/p/4328699.html   rowkey设计
http://blog.chedushi.com/archives/9720
http://www.bcmeng.com/hbase-rowkey/
http://blog.kissdata.com/2014/07/30/hbase-scheme-tips.html
<userid><max - timestamp><productid>


http://www.infoq.com/cn/articles/hbase-second-index-engine
https://www.ibm.com/developerworks/cn/java/j-lo-HBase/
https://www.mapr.com/blog/in-depth-look-hbase-architecture


进入命令：hbase shell
查看有多少表：list
查看表的结构：describe 'DEVICE'
查看表的数据：scan 'DEVICE'
查看某一行：get 'DEVICE',''
查看某列族的所有数据： scan 'DEVICE',{COLUMNS => 'course'}
删除表：drop 'testtable'   （删除表之前先要禁用表，命令disable 'testtable'）
启用和禁用表： enable 'testtable' 和disable 'testtable'
bin/hbase hbck  (检查)
bin/hbase hbck -fix  （修复）
bin/hbase org.apache.hadoop.hbase.mapreduce.CopyTable --peer.adr=zookeeper1,zookeeper2,zookeeper3:/hbase 'testtable'
bin/hbase org.apache.hadoop.hbase.mapreduce.Export testtable /user/testtable [versions] [starttime] [stoptime]
bin/hbase org.apache.hadoop.hbase.mapreduce.Import testtable  /user/testtable
首先拷贝hdfs文件，如bin/hadoop distcp hdfs://srcnamenode:9000/hbase/testtable/ hdfs://distnamenode:9000/hbase/testtable/
然后在目的hbase上执行bin/hbase org.jruby.Main bin/add_table.rb /hbase/testtable

备份或者拷贝一个表只能用copy/export表，或者disable表后，从hdfs中拷贝出所有hfile。copy/export表用的是MapReduce来scan和copy表，这会对Region Server产生直接的性能影响，而用disable后拷贝文件则是直接不能访问了。
snapshot并不是一份拷贝，它只是一个文件名的列表，并不拷贝数据。一个全的snapshot恢复以为着你可以回滚到原来的表schema和创建snapshot之前的数据。
Hbase一个重要的设计就是一旦写到一个文件就不会修改了。有不可修改的文件意味着一个snapshot仅需保持当前文件的使用相关信息就可以了, 并且，当compaction发生的时候，snapshot通知hbase系统仅把这些文件归档而不要删除它。
同样，当克隆或者恢复操作发生的时候，由于这些不变的文件，当用snapshot创建新表的时候仅需链接向这些不变的文件就行了。导出snapshot是唯一需要拷贝数据的操作，这是因为其它的集群并没有这些数据文件。
http://ju.outofmemory.cn/entry/50611

https://lessc0de.github.io/connecting_hbase_to_elasticsearch.html  

https://github.com/ndimiduk/hbase-1.0-api-examples  hbase 1.0
http://wuchong.me/blog/2015/04/06/spark-on-hbase-new-api/
http://wuchong.me/blog/2015/08/01/getting-started-with-metrics/  metrics

http://phoenix.apache.org/   Apache Phoenix is a relational database layer over HBase delivered as a client-embedded JDBC driver targeting low latency queries over HBase data. 
针对HBase上SQL解决方案，目前社区内比较热门的有Cloudera的Impala，Horntworks的Drill，以及Hive

http://blog.csdn.net/yaoyasong/article/details/39400829  应用Flume+HBase采集和存储日志数据
http://m.csdn.net/article/2015-02-10/2823915  结合美团下单率预测详解机器学习中的数据清洗与特征处理
http://m.csdn.net/article/a/2015-01-29/15822434


http://blog.csdn.net/u010967382/article/details/37878701?utm_source=tuicool  HBase基本数据操作详解
http://xstarcd.github.io/wiki/Cloud/hbase_tips.html   hbase日常操作收集

查看Zookeeper内部HBase相关数据，有两个主要的渠道：一、通过Hbase shell命令zk_dump查看  二、通过zk_cli.sh查看； ls /hbase
add_peer  list_peers  start_replication


多租户 命令空间
http://liyonghui160com.iteye.com/blog/2186479
http://blog.cheyo.net/62.html
http://www.bkjia.com/yjs/1015585.html
http://www.ibm.com/developerworks/cn/java/j-lo-dataMultitenant/
http://www.netnic.com.cn/news-qishang.htm/xingyejujiao/2015/0813/4110.html
<name>hbase.security.authorization</name>
<name>hbase.coprocessor.master.classes</name>
<value>org.apache.hadoop.hbase.security.access.AccessController</value>
<name>hbase.coprocessor.region.classes</name>
<value>org.apache.hadoop.hbase.security.token.TokenProvider,org.apache.hadoop.hbase.security.access.AccessController</value>
HBase提供的五个权限标识符：RWXCA,分别对应着 READ('R') , WRITE('W') , EXEC('X') , CREATE('C') , ADMIN('A')
HBase提供的安全管控级别包括：
Superuser：拥有所有权限的超级管理员用户。通过hbase.superuser参数配置
Global：全局权限可以作用在集群所有的表上。
Namespace：命名空间级。
Table：表级。
ColumnFamily：列簇级权限。
Cell：单元级。
和关系数据库一样，权限的授予和回收都使用grant和revoke
grant user permissions table column_family column_qualifier
revoke user table column family column qualifier
然后通过user_permission来查看权限
http://ju.outofmemory.cn/entry/119274


事务
http://blog.csdn.net/pirateleo/article/details/8592622
[HBASE-3584] - Allow atomic put/delete in one call.
[HBASE-5229] - Provide basic building blocks for "multi-row" local transactions.

http://riak.com.cn/riak/1.4.2/theory/comparisons/hbase/    Riak 和 HBase 比较

docker
http://bigdata-blog.net/2014/10/14/hfile%E5%92%8Chlog%E7%9A%84%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6/  HFile和HLog的回收机制
http://bigdata-blog.net/2014/12/03/%E5%8D%81%E5%88%86%E9%92%9F%E5%BC%80%E5%8F%91hbase%E5%BA%94%E7%94%A8/#more-216   十分钟开发HBase应用
docker run -d --net=host tobegit3hub/standalone-hbase-0.94
docker run -i -t --net=host tobegit3hub/smoke-hbase
https://github.com/nerdammer/dockers
docker run -it --rm --name dockerbase-devbase-hbase dockerbase/devbase-hbase
http://lifuzu.com/blog/2015/02/03/getting-familiar-with-hbase-on-dockerbase/
docker run -it --rm --name dockerbase-devbase-hadoop dockerbase/devbase-hadoop
http://lifuzu.com/blog/2015/02/03/playing-with-hadoop-on-dockerbase/


//自创建cf=f1的test_table表,并使用 SplitAlgorithm. HexStringSplit算法进行pre-splitting,或UniformSplit算法 
// -c 指定预先分区分区个数
hbase org.apache.hadoop.hbase.util.RegionSplitter test_table HexStringSplit -c 10 -f f1
在hbase-0.98+就支持了这个顺序反转的功能，  Scan.setReversed(true)

<name>hbase.coprocessor.user.region.classes</name>
<value>org.apache.hadoop.hbase.coprocessor.AggregateImplementation</value>
添加aggregation hbase> alter 'mytable', METHOD => 'table_att','coprocessor'=>'|org.apache.hadoop.hbase.coprocessor.AggregateImplementation||'
The start row is always inclusive, while the end row is exclusive. This is often expressed as [startRow, stopRow) in the interval notation.
setting the scan to use setBatch(5) would return five cells per Result instance  一次取多少列
−   Batch  使用scan调用next接口每次最大返回的记录数，与一次读取的列数有关。
−   Caching  一个RPC查询请求最大的返回的next数目，与一次RPC获取的行数有关。
HBase提供基于单行数据操作的原子性保证 即：对同一行的变更操作（包括针对一列/多列/多column family的操作），要么完全成功，要么完全失败，不会有其他状态
HBase提供的checkAndPut接口，checkAndPut提供了Compare And Set（CAS）的方式，确保了一行数据的原子性。    http://www.batchfile.cn/?p=77

HBASE-8015： 在0.96中，ROOT表已经改名为hbase:namespace，META则是hbase:meta。   
http://www.thebigdata.cn/wap.aspx?nid=8161&p=1&cp=3&cid=53

http://xn--jlq582ax31c.xn--fiqs8s/post/106
常见的二级索引方案有以下几种： 
1.MapReduce方案 
2.ITHBASE方案 
3.IHBASE方案 
4.Coprocessor方案 
5.Solr+hbase方案

https://github.com/ColZer/DigAndBuried/blob/master/hbase/hbase-filter.md
按照调用顺序来解释每个接口的功能.
filterRowKey:对rowKey进行过滤,如果rowKey被过滤了,那么后面的那些操作都不需要进行了
针对Row中cell进行过滤,由于一个row含有多个cell,因此这是一个循环过程
filterAllRemaining:是否需要结束对这条记录的filter操作
filterKeyValue:对每个cell进行过滤
transformCell:如果一个cell通过过滤,我们可以对过滤后的cell进行改写/转变
filterRowCells:对通过cell过滤后的所有cell列表进行修改
filterRow:站在row整体角度来进行过滤

coprocessor
http://saurzcode.in/2015/01/write-coprocessor-hbase/  
http://blog.selfup.cn/466.html
http://guoze.me/2015/04/23/hbase-observer-sync-elasticsearch/   导入elasticsearch
Using HBase coprocessors, custom features such as secondary indexing, complex filtering and access control features can be developed.
RegionObserver provides a hook for data manipulation operations such as Get, Put, Delete, Scan, and so on.The configuration property, hbase.coprocessor.region.classes, can be set to register the region observer.
RegionServerObserver: This observer provides the pre and post hooks for the merge, commits, and rollback operations and runs within the context of the HBase region server. This coprocessor can be registered using the hbase.coprocessor.regionserver.classes configuration property.
WALObserver: This observer provides hooks for the write-ahead log (WAL) and support for the pre and post WAL write events. can be registered by setting the hbase.coprocessor.wal.classes
configuration property.
MasterObserver: This observer provides hooks for data definition type operations such as table creation, deletion, schema modification, and so on. The MasterObserver coprocessor runs within the context of HBase Master and can be registered by setting the hbase.coprocessor.master.classes configuration property.
http://www.infoq.com/cn/articles/hbase-second-index-engine/
http://www.oschina.net/question/12_32573

hbase.replication  add_peer   start_replication   异步集群之间复制
让Hbase使用一个现有的不被Hbase托管的Zookeep集群，需要设置 HBASE_MANAGES_ZK 属性为 false
在某regionserver上启动Hmaster   hbase-daemon.sh start master
http://www.cnblogs.com/captainlucky/p/4710642.html
$HBASE_HOME/conf/ 目录下新增文件配置backup-masters，在其内添加要用做Backup Master的节点hostname。配置backup master的方式是在hbase的conf下增加文件backup-masters，在该文件里面增加backup master的机器列表，每台机器一条记录。
http://xstarcd.github.io/wiki/Cloud/hbase_backupmaster.html
http://xstarcd.github.io/wiki/Cloud/manual_start_hadoop_hbase.html  脚本说明


http://www.billstudy.com/2016/01/24/6ccb01cb7831473a45fa2b2d28c1d8a9/
Hbase里面有两张特殊的表：
.META.  记录了用户表的Region信息，.META.可以有多个regoin
-ROOT-  记录了.META.表的Region信息，-ROOT-只有一个region
Zookeeper中记录了-ROOT-表的location


<name>hbase.client.scanner.caching</name>  
SASL  hbase.security.authentication    hadoop.security.authentication
Region迁移的时候不能简单开启自动balance，因为balance主要的问题是不会根据表来进行balance，HBase的自动balance只会根据每个RegionServer上的Region数量来进行balance，
可以通过切分的方法生成多个小region后均匀分布(注意：region切分会触发major compact操作，会带来较大的I/O请求，请务必在业务低峰期进行)
一般地，HBase客户端的写入到RegionServer下某个region的memstore后就返回，除了网络外，其他都是内存操作

在HBase中，数据在更新时首先写入WAL 日志(HLog)和内存(MemStore)中，MemStore中的数据是排序的，当MemStore累计到一定阈值时，就会创建一个新的MemStore，并且将老的MemStore添加到flush队列，由单独的线程flush到磁盘上，成为一个StoreFile。于此同时， 系统会在zookeeper中记录一个redo point，表示这个时刻之前的变更已经持久化了(minor compact)。
StoreFile是只读的，一旦创建后就不可以再修改。因此Hbase的更新其实是不断追加的操作。当一个Store中的StoreFile达到一定的阈值后，就会进行一次合并(major compact)，将对同一个key的修改合并到一起，形成一个大的StoreFile，当StoreFile的大小达到一定阈值后，又会对 StoreFile进行分割(split)，等分为两个StoreFile。



HBase 0.92引入了Coprocessor这项特性，可以很方便地在RegionServer端实现各类聚集操作，通过AggregationClient#rowCount这个接口就可以相对高效地统计表的行数了。
Coprocessor提供了Observer和Endpoint两项特性，前者允许通过重写函数在RegionServer端注入用户代码，后者则相当于数据库中的触发器
http://bigdata-blog.net/2013/11/15/hbase%E8%A1%8C%E6%95%B0%E7%BB%9F%E8%AE%A1/
<name>hbase.coprocessor.user.region.classes</name>
<value>org.apache.hadoop.hbase.coprocessor.AggregateImplementation</value>
hbase> alter 'mytable', METHOD => 'table_att','coprocessor'=>'|org.apache.hadoop.hbase.coprocessor.AggregateImplementation||'
http://michaelmorello.blogspot.tw/2012/01/row-count-hbase-aggregation-example.html


如果HBase单个节点出现故障，Zookeeper会通知master主进程，master会将HLog日志进行拆分，分发到其他RegionServer上进行数据恢复。HBase对于单点故障的容错能力还是不错的
HBase 0.90以后开始支持Replication机制，该机制设计的主导思想是基于操作日志(put/get/delete)做数据同步，这点很像MySQL基于Binary Log做statement-based replication
客户端的put/delete操作会被RegionServer写入本地的HLog中去，与此同时每个RegionServer会将Hlog放入对应znode上的Replication队列，HBase集群会有一个独立的线程，根据固定大小的buffer值，将HLog内容推送到Slave Cluster集群中的某个RegionServer上(当前版本只支持单个Slave Cluster复制)，并在将当前复制的偏移量保存在ZooKeeper上，整个过程是异步完成的。
http://www.infoq.com/cn/articles/lp-hbase-data-disaster-recovery


通过Cloudera Manager安装CDH   http://blog.javachen.com/2013/06/24/install-cdh-by-cloudera-manager/
http://www.micmiu.com/bigdata/hbase/hbase-setup-standalone/   hbase安装
HBASE_MANAGES_ZK=false
hbase.zookeeper.quorum


Scan(byte[] startRow, Filter filter)
Scan(byte[] startRow, byte[] stopRow)
Scan setFilter(Filter filter)

ResultScanner类
scan并不是一次RPC中把所有结果都返回给client，而是以row为单位返回的。
Result next() throws IOException
Result[] next(int nbRows) throws IOException
void close()（finally里面关闭）

public void setBatch(int batch) ：为设置获取记录的列个数，默认无限制，也就是返回所有的列
public void setCaching(int caching)：每次从服务器端读取的行数，默认为配置文件中设置的值

ColumnPrefixFilter用于指定列名前缀值相等  
MultipleColumnPrefixFilter和ColumnPrefixFilter行为差不多，但可以指定多个前缀。  
QualifierFilter是基于列名的过滤器

zookeeper
http://supben.iteye.com/blog/2094077  TestingServer 模拟单点， TestingCluster模拟集群。
http://ifeve.com/zookeeper-curato-framework/



http://blog.csdn.net/hengyunabc/article/details/41146115   日志收集分析
http://koven2049.iteye.com/blog/983633
http://www.ngdata.com/the-hbase-side-effect-processor-and-hbase-replication-monitoring/
HBase的Relication机制，其实和Mysql的同步机制很像，HBase的每个Region Server都会有WAL Log，当Put/Delete时，都会先写入到WAL Log里。然后后台有线程会把WAL Log随机发给Slave的Region Server。而Slave的Region Server会在zookeeper上记录自己同步到的位置。  

 MVCC(Multi-Version Concurrent Control),即多版本并发控制协议,广泛使用于数据库系统


http://blog.csdn.net/xiejx618/article/details/21201007 org.springframework.mock.web.MockMultipartFile
http://jinnianshilongnian.iteye.com/blog/1469524   spring test
http://www.iteedu.com/webtech/j2ee/spring25cn/ch08s03.php  SimpleJdbcTestUtils
http://blog.csdn.net/moxiaomomo/article/details/16817497   HBaseTestingUtility
http://m.blog.csdn.net/blog/aaa1117a8w5s6d/17761511
http://blog.csdn.net/feihong247/article/details/7828143
http://docs.spring.io/spring/docs/current/spring-framework-reference/html/testing.html
http://www.ibm.com/developerworks/cn/java/j-lo-springunitest/
http://blog.jdwyah.com/2013/02/mock-hbase-for-unit-testing.html
http://dirlt.com/hadoop.html
http://blog.sematext.com/2010/08/30/hbase-case-study-using-hbasetestingutility-for-local-testing-development/

zookeeper
PathChildrenCache用来监控一个ZNode的子节点. 当一个子节点增加， 更新，删除时， Path Cache会改变它的状态， 会包含最新的子节点， 子节点的数据和状态。 
NodeCache用来监控一个ZNode. 当节点的数据修改或者删除时，Node Cache能更新它的状态包含最新的改变。
TreeCache这种类型的即可以监控节点的状态，还监控节点的子节点的状态， 类似上面两种cache的组合。 这也就是Tree的概念。 它监控整个树中节点的状态。
http://ifeve.com/zookeeper-path-cache/
http://ifeve.com/zookeeper-barrier/
http://macrochen.iteye.com/blog/1366136

hadoop
http://www.cnblogs.com/vigiles/p/3643489.html?utm_source=tuicool
http://blog.csdn.net/hadoop_/article/details/11538201?utm_source=tuicool
http://blog.csdn.net/yeruby/article/details/19995367
http://wuchong.me/blog/2015/04/06/spark-on-hbase-new-api/
HBase 实现了 TableInputFormatBase 类，该类提供了对表数据的大部分操作，其子类 TableInputFormat 则提供了完整的实现，用于处理表数据并生成键值对。
HBase 实现了 TableMapper 类和 TableReducer 类   HBase 实现的 TableOutputFormat 将输出的<key,value>对写到指定的 HBase 表中，该类不会对 WAL（Write-Ahead  Log）进行操作
http://www.jianshu.com/p/722a75d2b2bd
