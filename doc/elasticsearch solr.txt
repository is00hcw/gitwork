https://imququ.com/post/elasticsearch.html   使用 Elasticsearch 实现博客站内搜索
http://blog.sctux.com/?p=445 
http://blog.sctux.com/?p=451  ELK+Kafka 企业日志收集平台
curl -XDELETE 'http://localhost:9200/logstash-*'   清理掉了所有的索引文件
curl localhost:9200
http://h2ex.com/191

http://songlee24.github.io/2016/02/24/hello-Elasticsearch/  初识Elasticsearch

docker
https://github.com/dockerfile/elasticsearch
https://www.ralphlepore.net/running-elasticsearch-in-a-docker-container/
http://www.codedependant.net/2015/01/17/install-elastic-search-plugins-through-docker/
sudo docker run -d -p 9200:9200 -p 9300:9300 elasticsearch

Elastic 官方文档建议：一个 Node 最好不要多于三个 shards。若是 "more shards”，除了增加更多的机器，是没办法做到这一点的。分索引，虽然一个 Node 总的shards 还是挺多的，但是一个索引可以保持3个以内的shards。
记得 threadpool.index.queue_size ++，不然会出现索引时队列不够用的情况。
indices.memory.index_buffer_size:10% 这个参数可以进行适当调整。
调整如下参数也可以提高索引速度：index.translog.flush_threshold_ops:50000 和 refresh_interval。
建议在最热的查询中避免使用 Range 查询。 每天优化是有好处的，可以大大改善查询性能。max_num_segments 建议配置为1。
hreadpool.search.queue_size 这个配置是很重要的，一般默认是够用了，可以尝试提高。
JVM 还有一个配置 bootstrap.mlockall: true，比较重要。这是让 JVM 启动的时候就 锁定 heap 内存。
http://mp.weixin.qq.com/s?__biz=MzAwMDU1MTE1OQ==&mid=209488723&idx=1&sn=d60c0637d7a9f4a4b981a69f10c6b90a&scene=0#rd   亿级规模的Elasticsearch优化实战

可以执行以下命令来关掉整个集群：curl -XPOST http://localhost:9200/_cluster/nodes/_shutdown 
GET http://localhost:9200/_cluster/state/nodes/：这个命令获取集群中节点的信息。
也可对这两个索引执行一个查询：curl -XGET 'localhost:9200/books,clients/_search?pretty' 如果要寻找任意索引，只需要设置星号（*）为索引名称，或忽略索引名称。
还可以省略索引和类型来搜索所有索引。例如，以下命令将搜索集群中的所有数据：curl -XGET 'localhost:9200/_search?pretty' 
如果在自定义排序的同时还想保持追踪每个文档的得分，你应该把track_scores=true添加到你的查询。size参数默认为10，它定义了返回结果的最大数量。from参数的默认值为0，它指定结果应该从哪个记录开始返回。
索引使用的磁盘空间和资源，例如文件描述符。如果从索引中删除许多文档，直到合并发生，则这些文档只是被标记为已删除，而没有在物理上删除。
可使用index.merge.policy.type属性来设置想使用的合并策略，如下所示：index.merge.policy.type: tiered 
可以在Elasticsearch中返回脚本计算字段：在JSON的查询对象中加上script_fields部分  "script" : "doc['year'].value - 1800"    "script" : "_source.year - 1800" 
发散阶段每个查询的分片将只返回文档的标识符和得分。发送分散查询的节点将等待所有的分片完成它们的任务，收集结果并适当排序
在任何搜索中使用过滤器，只需在于query节点相同级别上添加一个filter节点。在第一种情况下，过滤器应用到查询所发现的所有文档上。第二种情况下，过滤发生在在运行查询之前，性能更好。
验证查询 curl -XGET 'localhost:9200/library/_validate/query?pretty&explain' --data-binary @query.json 
如果能忍受低精度（但性能更好），使用top N重写方法。如果需要高精度（但性能较低），选择布尔方法。
需要记住的第一件事是父子文档需要存储在相同的分片中，查询才能够工作。   执行has_child等查询时，Elasticsearch需要预加载并缓存文档
标识符。这些标识符将存储在内存中，必须确保Elasticsearch有足够的内存。   
可以直接在映射文件中定义字段的加权   "author" : { "type" : "string", "boost" : 10.0 } 
synonyms_path属性应该设成含有同义词定义的文件名，文件路径应该相对于Elasticsearch的config目录
curl -X GET 'localhost:9200/_analyze?pretty' -d 'Crime and Punishment'
curl -X GET 'localhost:9200/library/book/1/_explain?pretty&q=quiet'  
term建议器基于字符串编辑距离（string edit distance）工作。这意味着，通过更少字符的更改、添加或删除就可以让建议单词和原始单词一样，那么这样的建议最好。
形成集群和寻找节点的过程称为发现。负责发现的模块有两个主要目的：选出一个主节点和发现集群中的新节点。默认在没有安装额外插件的情况下，Elasticsearch允许使用zen发现，它提供了多播和单播发现。
当脑裂发生时，你有两个（或更多）不会互相连接的集群，直到网络（或其他任何）问题得到修复。为了防止脑裂发生，Elasticsearch提供了discovery.zen.minimum_master_nodes属性。
该属性定义的是为了形成一个集群，有主节点资格并互相连接的节点的最小数目。
线程池的配置可以使用集群的更新API来更新，如下所示：curl -XPUT 'localhost:9200/_cluster/settings' -d 
curl -X PUT localhost:9200/_snapshot/backup
预热查询跟普通查询没什么区别，只是它存储在Elasticsearch一个特殊的名为_warmer的索引中。
index.search.slowlog: TRACE, index_search_slow_log_file 日志文件由logging.yml配置文件中的index_search_slow_log_file节点指定



http://news.oneapm.com/dangdang-oneapm/   电商搜索引擎的架构设计和性能优化
https://yq.aliyun.com/articles/4266?utm_source=tuicool&utm_medium=referral   OpenSearch：轻松构建大数据搜索服务

http://ylw6006.blog.51cto.com/470441/1722905  packetbeat
packetbeat -e -d "*"    https://www.elastic.co/guide/en/beats/packetbeat/1.1/enable-packetbeat-debugging.html
http://www.tuicool.com/articles/ZR7vIfu
topbeat -e    https://www.elastic.co/guide/en/beats/topbeat/1.1/enable-topbeat-debugging.html
http://www.tuicool.com/articles/VFrE7nY
http://www.ttlsa.com/elk/migration-logtash-forwarder-to-filebeat/

http://blog.zhenchuan.me/set-up-elk-elasticsearch/
http://kibana.logstash.es/content/elasticsearch/performance/curator.html
为了更加方便的做清除数据，合并 segment，备份恢复等管理任务，Elasticsearch 在提供相关 API 的同时，另外准备了一个命令行工具，叫 curator 。curator 是 Python 程序，可以直接通过 pypi 库安装：
wget --no-check-certificate https://bootstrap.pypa.io/get-pip.py
python get-pip.py
pip install elasticsearch-curator


HBase的Relication机制，其实和Mysql的同步机制很像，HBase的每个Region Server都会有WAL Log，当Put/Delete时，都会先写入到WAL Log里。然后后台有线程会把WAL Log随机发给Slave的Region Server。而Slave的Region Server会在zookeeper上记录自己同步到的位置。
http://blog.csdn.net/hengyunabc/article/details/41146115

类型（Type）是索引内部的一个逻辑划分，在一个索引内部可以定义多个类型（Type），类型将一个索引在逻辑上划分为多个集合，每个类型包含多个属性（字段）。ElasticSearch中类型，与HBase中列簇（Column Family）的概念很相似。
一个索引是很多文档的集合，将一个索引进行分割，分成多个片段（一个索引的子集），每一个片段称为一个分片（Shard），这样划分可以很好地管理索引，跨节点存储，为分布式存储于搜索提供了便利。副本（Replica）是为了保证一个分片（Shard）的可用性，冗余复制存储，当一个分片对应的数据无法读取时，可以读取其副本，正常提供搜索服务。
http://shiyanjun.cn/archives/1371.html   ElasticSearch-2.0.0集群安装配置与API使用实践


ES 是一个 P2P 类型(使用 gossip 协议)的分布式系统，除了集群状态管理以外，其他所有的请求都可以发送到集群内任意一台节点上，这个节点可以自己找到需要转发给哪些节点，并且直接跟这些节点通信。
只配置 cluster.name 的集群，其实就是采用了默认的自动发现协议，即组播(multicast)方式。节点会在本机所有网卡接口上，使用组播地址 224.2.2.4 ，以 54328 端口建立组播组发送 clustername 信息。
只有在同一个交换机下的节点，能自动发现，跨交换机的节点，是无法收到组播信息的。
Elasticsearch 2.0 开始，为安全考虑，默认不分发 multicast 功能。依然希望使用 multicast 自动发现的用户，需要单独安装:
bin/plugin install discovery-multicast
除了组播方式，ES 还支持单播(unicast)方式。配置里提供几台节点的地址，ES 将其视作 gossip router 角色，借以完成集群的发现。
ElastAlert 是 Yelp 公司开源的一套用 Python2.6 写的报警框架。属于后来 Elastic.co 公司出品的 Watcher 同类产品
为了更加方便的做清除数据，合并 segment，备份恢复等管理任务，Elasticsearch 在提供相关 API 的同时，另外准备了一个命令行工具，叫 curator 。curator 是 Python 程序，可以直接通过 pypi 库安装：
pip install elasticsearch-curator
curl -X GET 127.0.0.1:9200/_cluster/health?pretty

http://elasticsearch.cn/article/17
用 Logstash 接收 Kafka 里的业务日志再写入 Elasticsearch 已经成为一个常见的选择。但是大多数人随后就会碰到一个问题：logstash-input-kafka 的性能上不去！这个问题，主要是由于 Logstash 用 JRuby 实现
从 logstash-1.5.1 版开始，新发布了一个 logstash-input-heartbeat 插件，实现了一个最基本的队列堵塞状态监控。
Logstash 是一个运行在 JVM 上的软件，也就意味着 JMX 这种对 JVM 的通用监控方式对 Logstash 也是一样有效果的。甚至 logstash 自己也有插件 logstash-input-jmx 来读取远程 JMX 数据。
注意，zabbix-server 本身并不直接对 JMX 发起请求，而是单独有一个 Java Gateway 作为中间代理层角色。zabbix-server 的 java poller 连接 zabbix-java-gateway，由 zabbix-java-gateway 去获取远程 JMX 信息。
https://www.elastic.co/blog/logstash-kafka-intro
bin/logstash -e "input { stdin {} } output { kafka { topic_id => 'logstash_logs' } }"
bin/logtash -e "input { kafka { topic_id => 'logstash_logs' } } output { elasticsearch { protocol => http } }"


http://www.ashishpaliwal.com/blog/2015/04/geospatial-indexing-with-elasticsearch/  位置搜索
http://blog.zhenchuan.me/deep-into-elasticsearch/   深入理解 elasticsearch
http://shokunin.co/blog/2013/06/24/elasticsearch.html
http://blog.csdn.net/july_2/article/details/24702243
plugin -install lukas-vlcek/bigdesk
http://localhost:9200/_plugin/bigdesk/ 
plugin -install royrusso/elasticsearch-HQ

https://www.elastic.co/guide/en/sense/current/installing.html#installing
kibana plugin --install elastic/sense
http://localhost:5601/app/sense

2.0可以免费使用一个集群 https://www.elastic.co/downloads/marvel
plugin install license
plugin install marvel-agent
http://localhost:5601/app/marvel
http://www.vpsee.com/2014/05/install-and-play-with-elasticsearch/
plugin -i elasticsearch/marvel/latest

https://github.com/lmenezes/elasticsearch-kopf

plugin -install mobz/elasticsearch-head
http://localhost:9200/_plugin/head/


plugin -install karmi/elasticsearch-paramedic
https://github.com/is00hcw/elasticsearch-paramedic

plugin install elasticsearch/elasticsearch-analysis-smartcn/2.7.0
https://github.com/elastic/elasticsearch-analysis-smartcn

http://www.shenjuanli.com/2014/03/03/logstashelasticsearchkibana%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E6%9C%AA%E5%AE%8C%EF%BC%89/
http://segmentfault.com/a/1190000002904818

http://blog.csdn.net/liuzhenfeng/article/details/39404435  Elasticsearch安装中文分词插件ik

http://segmentfault.com/a/1190000002972420   kibana使用的lucene查询语法

http://blog.csdn.net/u014201191/article/details/46508311   

pip install elasticsearch


http://www.vpsee.com/2015/03/a-modern-monitoring-system-built-with-grafana-collected-influxdb/  使用 Grafana＋collectd＋InfluxDB 打造现代监控系统

http://www.zihou.me/html/2014/01/17/9061.html  elasticsearch.yml配置说明
http://zhaoyanblog.com/archives/319.html  elasticsearch三个重要的优化   配置index.refresh_interval参数，默认是1s
此处可以根据机器硬件配置情况作出适当的调整，一般情况下，此处的内存分配大小为机器物理内存的一半，同时将 ES_MIN_MEM 与 ES_MAX_MEM 配置成相同的值
由于ES集群一般都是在内部网络环境中，且节点之间相互通信使用的是 TCP 9300端口，节点与客户端通信则是通过 TCP 9200端口。因此检查 iptalbes 以及SElinux 中是否开启，以及确定这些端口是否被绑定安全策略等等。
可以在最后的上线之前可以再做一次最后的测试，在测试之前，先修改Elasticsearch 中的配置文件，即是elasticsearch.yml 中的 cluster.name 参数的名称，避免加入了线上集群中。并利用 curl -X GET localhost:9200  来测试新版本的 Elasticsearch 进程是否正常。　　
系统不能限制打开的文件描述符小于32 000个。在Linux上，一般在/etc/security/limits.conf中修改，当前的值可以用ulimit命令来查看。如果达到极限，Elasticsearch将无法创建新的文件，所以合并会失败，索引会失败，新的索引无法创建。

http://my.oschina.net/galenz/blog/422189   Elasticsearch 分片交互过程分析
http://www.cnblogs.com/xing901022/p/4967796.html  Elasticsearch 数据搜索篇 【入门级干货】

备份恢复
在浏览器中运行http://ipaddress:9200/_flush，这样确保索引数据能保存到硬盘中。
http://keenwon.com/1393.html
http://m.blog.csdn.net/blog/huwei2003/41577017
http://segmentfault.com/q/1010000002406786

同义词
http://blog.csdn.net/yusewuhen/article/details/50685685   Elasticsearch 自带一个名为 synonym 的同义词 filter
http://www.ifunit.com/29/elasticsearch%E9%85%8D%E7%BD%AE%E5%90%8C%E4%B9%89%E8%AF%8D
http://www.cnblogs.com/buzzlight/p/elasticsearch_analysis.html  
全文搜索引擎会用某种算法对要建索引的文档进行分析， 从文档中提取出若干Token(词元)， 这些算法称为Tokenizer(分词器)， 这些Token会被进一步处理， 比如转成小写等， 这些处理算法被称为Token Filter(词元处理器), 被处理后的结果被称为Term(词)， 文档中包含了几个这样的Term被称为Frequency(词频)。 引擎会建立Term和原文档的Inverted Index(倒排索引)， 这样就能根据Term很快到找到源文档了。 文本被Tokenizer处理前可能要做一些预处理， 比如去掉里面的HTML标记， 这些处理的算法被称为Character Filter(字符过滤器)， 这整个的分析算法被称为Analyzer(分析器)。

http://www.infoq.com/cn/news/2015/02/apache-lucene5-release
http://www.cnblogs.com/ibook360/archive/2012/12/29/2839094.html
http://itindex.net/detail/49374-lucene-4.8.0-%E5%8F%98%E5%8C%96
提供了针对第一次搜索结果集合的重打分（权重调整）API；相当于对搜索结果的二次自定义排序。 
AnalyzingInfixSuggester 类提供了支持NRT的自动建议功能。 


分析的工作由分析器完成，它由一个分词器（tokenizer）和零个或多个标记过滤器（token filter）组成，也可以有零个或多个字符映射器（character mapper）。
Lucene中的分词器把文本分割成多个标记，基本就是词加上一些额外信息，比如该词在原始文本中的位置和长度。默认情况下，Apache Lucene使用TF/IDF（term frequency/inverse document frequency，词频/逆向文档频率）评分机制
收到查询请求的节点会把查询转发给保存了属于给定索引的分片的所有节点，并要求与查询匹配的文档的最少信息（默认情况下是标识符和得分）。这个过程称为发散阶段（scatter phase）。收到这些信息后，该聚合节点（收到客户端请求的节点）对结果排序，并发送第2个请求来获取结果列表所需的文档（除了标识符和
得分以外的所有信息）。这个阶段称为收集阶段（gather phase）。这个阶段执行完毕后，结果返回到客户端。

index_options：该属性定义了信息列表（postings list）的索引选项（2.2.4节将详细讨论）。可能的值是docs（仅对文档编号建立索引）， freqs（对文档编号和词频建立索引），positions（对文档编号、词频和它们的位置建立索引）， offsets（对文档编号、词频、它们的位置和偏移量建立索引）。对于经分析的字段，此属性的默认值是positions，对于未经分析的字段，默认值为docs。
例如，对cars和car这两个单词，词干提取器（stemmer，词干提取算法的一种实现）产生一个词干car。
2012年发布Apache Lucene 4.0后，该全文检索库的所有用户便可以修改默认的基于TF/IDF的算法。 Lucene 4.0还附加了相似度模型（similarity model），允许在文档中使用不同的评分公式  BM25相似度模型
Okapi BM25模型：这种相似度模型基于概率模型，概率模型估算根据指定查询找到指定文档的概率。


http://my.oschina.net/galenz/blog/333070  Zabbix的安装与部署

wget http://mirror.bit.edu.cn/apache/flume/1.6.0/apache-flume-1.6.0-bin.tar.gz
wget http://download.elastic.co/kibana/kibana/kibana-4.2.0-linux-x64.tar.gz
wget https://download.elastic.co/logstash/logstash/logstash-2.0.0.tar.gz
wget https://download.elasticsearch.org/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/2.0.0/elasticsearch-2.0.0.tar.gz
./plugin install lukas-vlcek/bigdesk
config/kibana.yml in an editor Set the elasticsearch.url 
http://115.28.225.5:5601/app/kibana
http://demo.elastic.co/packetbeat/#/discover   官方测试的页面
http://segmentfault.com/a/1190000002972420     kibana使用的lucene查询语法
https://www.elastic.co/guide/en/logstash/current/output-plugins.html
http://udn.yyuap.com/doc/logstash-best-practice-cn/input/index.html
?只是插入新增的日志

http://blog.csdn.net/sunflower_cao/article/details/39929931?utm_source=tuicool&utm_medium=referral
http://ju.outofmemory.cn/entry/119397
http://flume.apache.org/FlumeUserGuide.html#elasticsearchsink
The elasticsearch and lucene-core jars required for your environment must be placed in the lib directory of the Apache Flume installation.
flume1.6 还不支持 es2.0
