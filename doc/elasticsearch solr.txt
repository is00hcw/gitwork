https://github.com/NLPchina/elasticsearch-sql
http://www.nlpcn.org:9999/web/    http://localhost:9200/_plugin/sql/
http://120.24.39.98:9200/_sql?sql=select * from indexName limit 10
http://localhost:9200/_sql/_explain?sql=select * from indexName limit 10
https://www.oschina.net/p/elastichd?fromerr=KxMuKnWp    https://github.com/farmerx/ElasticHD

http://www.yiibai.com/elasticsearch/elasticsearch_query_dsl.html  http查询列子
http://qiita.com/vanhuyz/items/04a6871ae5f53ba5a97f  bool查询复合
https://www.zybuluo.com/1234567890/note/672738 ElasticSearch-java实例  AggregationBuilder
http://dev.dafan.info/detail/410094?p=61   elasticSearch基本查询详解
http://okfnlabs.org/blog/2013/07/01/elasticsearch-query-tutorial.html
https://taohiko.wordpress.com/2014/07/18/query-dsl-elasticsearch-vs-sql/
term用于精确查询，match用于全文检索
term query查询  提供的查询词是不分词的(not analyzed)，即只有完全包含才算匹配；
match query的查询词是被分词处理的（analyzed），即首先分词，然后构造相应的查询，所以应该确保查询的分词器和索引的分词器是一致的；
https://www.elastic.co/guide/en/elasticsearch/guide/current/_queries_and_filters.html
Query查询上下文：查询操作不仅仅会进行查询，还会计算分值，用于确定相关度；Query会计算文档和query之间的相关性，并将结果存放到_score字段中，随后_score被用来对匹配到的文档进行排序。
Filter过滤器上下文：查询操作仅判断是否满足查询条件，不会计算得分，查询的结果可以被缓存。
Filter作用于有确定值的字段，判断这些字段是否满足特定的条件。

http://yyqian.com/post/1463461156000/  Elasticsearch 学习笔记
http://jolefstar.com/elasticsearch-architecture/  Elasticsearch 架构以及源码概览
https://oss.aliyuncs.com/yqfiles/ELK调研.pd...%5Bsuntingtao%5D.1461556683.pdf
http://www.jianshu.com/p/f4bdfda8b390  Elasticsearch的基础分布式架构以及shard相关知识和节点的扩容、容错
http://www.jianshu.com/p/7a46f9d0b9b7  Elasticsearch---document存放时的路由原理及增删改查原理
https://zhuanlan.zhihu.com/p/27352681  深入浅出 spring-data-elasticsearch 之 ElasticSearch 架构初探（一）
https://www.elastic.co/guide/cn/elasticsearch/guide/current/_scale_horizontally.html
https://wizardforcel.gitbooks.io/mastering-elasticsearch/content/chapter-4/42_README.html

分布式系统要解决的第一个问题就是节点之间互相发现以及选主的机制。如果使用了 Zookeeper/Etcd 这样的成熟的服务发现工具，这两个问题都一并解决了。
集群是去中心化的，有一个主节点（Master）。主节点是动态选举，因此不会出现单点故障。分布式存储系统为了解决单机容量以及容灾的问题，都需要有分片以及副本机制。Elasticsearch 没有采用节点级别的主从复制，而是基于分片。它当前还未提供分片切分（shard-splitting）的机制，只能创建索引的时候静态设置。
primary shard的数量在创建索引的时候就固定了，replica shard的数量可以随时修改primary shard的默认数量是5，replica默认是1，默认有10个shard，5个primary shard，5个replica shard
分片是一个功能完整的搜索引擎，它拥有使用一个节点上的所有资源的能力。 我们这个拥有6个分片（3个主分片和3个副本分片）的索引可以最大扩容到6个节点，每个节点上存在一个分片，并且每个分片拥有所在节点的全部资源。
主分片的数目在索引创建时 就已经确定了下来。实际上，这个数目定义了这个索引能够 存储 的最大数据量。（实际大小取决于你的数据、硬件和使用场景。） 但是，读操作――搜索和返回数据――可以同时被主分片 或 副本分片所处理，所以当你拥有越多的副本分片时，也将拥有越高的吞吐量。在运行中的集群上是可以动态调整副本分片数目
coordinate node对document进行路由，将请求转发到对应的node，此时会使用round-robin随机轮询算法，在paimary shard以及所有replica中随机选择一个，让读请求负载均衡
官方文档的说法是分片切分成本和重新索引的成本差不多，所以建议干脆通过接口重新索引。
Elasticsearch 的分片默认是基于id 哈希的，id可以用户指定，也可以自动生成。但这个可以通过参数（routing）或者在mapping配置中修改。当前版本默认的哈希算法是MurmurHash3。
Elasticsearch 禁止同一个分片的主分片和副本分片在同一个节点上，所以如果是一个节点的集群是不能有副本的。

存储路由过程由下面地公式决定：shard = hash(routing) % number_of_primary_shards
routing 是可变值，支持自定义，默认文档 _id。 但我们也可以手动指定 PUT /index/type/id?routing=user_id
这也解释了为什么主切片的数量只能在创建索引时定义且不能修改：如果主切片的数量在未来改变了，所有先前的路由值就失效了，文档也就永远找不到了。
所有的文档API（get、index、delete、bulk、update、mget）都接收一个routing参数，它用来自定义文档到分片的映射。自定义路由值可以确保所有相关文档.比如用户的文章,按照用户账号路由,就可以实现属于同一用户的文档被保存在同一分片上。
在默认情况下，Elasticsearch 采用 TF-IDF (term frequencyCinverse document frequency) 算法

http://blog.csdn.net/sunnyyoona/article/details/51747381  [Elasticsearch]elasticsearch+kibana+marvel安装
kibana 2.6.1  Elasticsearch 2.4.1
kibana plugin --install elastic/sense
访问地址：localhost:5601/app/sense
Step 1: Install Marvel into Elasticsearch:	
bin/plugin install license
bin/plugin install marvel-agent
Step 2: Install Marvel into Kibana	
bin/kibana plugin --install elasticsearch/marvel/latest
Step 4: Navigate to http://localhost:5601/app/marvel

head:http://localhost:9200/_plugin/head/
bigdesk：http://localhost:9200/_plugin/bigdesk/
plugin install mobz/elasticsearch-head
绿色表示主分片和副本分片都可用；
黄色表示只有主分片可用，没有副本分片；
红色表示主分片中的部分索引不可用，但是不耽误某些索引的访问。

创建simple.conf文件，并编写测试conf
input { stdin { } }
output {
  elasticsearch { host => localhost }
  stdout { codec => rubydebug }
}
logstash -f simple.conf --debug


https://my.oschina.net/u/2903254/blog/789355  23 款实用的 Elasticsearch 查询示例
http://www.infoq.com/cn/articles/analysis-of-elasticsearch-cluster-part01  Elasticsearch的存储模型和读写操作
http://my.oschina.net/wsyblog/blog/702841
https://imququ.com/post/elasticsearch.html   使用 Elasticsearch 实现博客站内搜索
http://blog.sctux.com/?p=445 
http://blog.sctux.com/?p=451  ELK+Kafka 企业日志收集平台
curl -XDELETE 'http://localhost:9200/logstash-*'   清理掉了所有的索引文件
curl localhost:9200
http://h2ex.com/191

http://songlee24.github.io/2016/02/24/hello-Elasticsearch/  初识Elasticsearch

docker
https://github.com/dockerfile/elasticsearch
https://www.ralphlepore.net/running-elasticsearch-in-a-docker-container/
http://www.codedependant.net/2015/01/17/install-elastic-search-plugins-through-docker/
sudo docker run -d -p 9200:9200 -p 9300:9300 elasticsearch

Elastic 官方文档建议：一个 Node 最好不要多于三个 shards。若是 "more shards”，除了增加更多的机器，是没办法做到这一点的。分索引，虽然一个 Node 总的shards 还是挺多的，但是一个索引可以保持3个以内的shards。
记得 threadpool.index.queue_size ++，不然会出现索引时队列不够用的情况。
indices.memory.index_buffer_size:10% 这个参数可以进行适当调整。
调整如下参数也可以提高索引速度：index.translog.flush_threshold_ops:50000 和 refresh_interval。
建议在最热的查询中避免使用 Range 查询。 每天优化是有好处的，可以大大改善查询性能。max_num_segments 建议配置为1。
hreadpool.search.queue_size 这个配置是很重要的，一般默认是够用了，可以尝试提高。
JVM 还有一个配置 bootstrap.mlockall: true，比较重要。这是让 JVM 启动的时候就 锁定 heap 内存。
http://mp.weixin.qq.com/s?__biz=MzAwMDU1MTE1OQ==&mid=209488723&idx=1&sn=d60c0637d7a9f4a4b981a69f10c6b90a&scene=0#rd   亿级规模的Elasticsearch优化实战

可以执行以下命令来关掉整个集群：curl -XPOST http://localhost:9200/_cluster/nodes/_shutdown 
GET http://localhost:9200/_cluster/state/nodes/：这个命令获取集群中节点的信息。
也可对这两个索引执行一个查询：curl -XGET 'localhost:9200/books,clients/_search?pretty' 如果要寻找任意索引，只需要设置星号（*）为索引名称，或忽略索引名称。
还可以省略索引和类型来搜索所有索引。例如，以下命令将搜索集群中的所有数据：curl -XGET 'localhost:9200/_search?pretty' 
如果在自定义排序的同时还想保持追踪每个文档的得分，你应该把track_scores=true添加到你的查询。size参数默认为10，它定义了返回结果的最大数量。from参数的默认值为0，它指定结果应该从哪个记录开始返回。
索引使用的磁盘空间和资源，例如文件描述符。如果从索引中删除许多文档，直到合并发生，则这些文档只是被标记为已删除，而没有在物理上删除。
可使用index.merge.policy.type属性来设置想使用的合并策略，如下所示：index.merge.policy.type: tiered 
可以在Elasticsearch中返回脚本计算字段：在JSON的查询对象中加上script_fields部分  "script" : "doc['year'].value - 1800"    "script" : "_source.year - 1800" 
发散阶段每个查询的分片将只返回文档的标识符和得分。发送分散查询的节点将等待所有的分片完成它们的任务，收集结果并适当排序
在任何搜索中使用过滤器，只需在于query节点相同级别上添加一个filter节点。在第一种情况下，过滤器应用到查询所发现的所有文档上。第二种情况下，过滤发生在在运行查询之前，性能更好。
验证查询 curl -XGET 'localhost:9200/library/_validate/query?pretty&explain' --data-binary @query.json 
如果能忍受低精度（但性能更好），使用top N重写方法。如果需要高精度（但性能较低），选择布尔方法。
需要记住的第一件事是父子文档需要存储在相同的分片中，查询才能够工作。   执行has_child等查询时，Elasticsearch需要预加载并缓存文档
标识符。这些标识符将存储在内存中，必须确保Elasticsearch有足够的内存。   
可以直接在映射文件中定义字段的加权   "author" : { "type" : "string", "boost" : 10.0 } 
synonyms_path属性应该设成含有同义词定义的文件名，文件路径应该相对于Elasticsearch的config目录
curl -X GET 'localhost:9200/_analyze?pretty' -d 'Crime and Punishment'
curl -X GET 'localhost:9200/library/book/1/_explain?pretty&q=quiet'  
term建议器基于字符串编辑距离（string edit distance）工作。这意味着，通过更少字符的更改、添加或删除就可以让建议单词和原始单词一样，那么这样的建议最好。
形成集群和寻找节点的过程称为发现。负责发现的模块有两个主要目的：选出一个主节点和发现集群中的新节点。默认在没有安装额外插件的情况下，Elasticsearch允许使用zen发现，它提供了多播和单播发现。
当脑裂发生时，你有两个（或更多）不会互相连接的集群，直到网络（或其他任何）问题得到修复。为了防止脑裂发生，Elasticsearch提供了discovery.zen.minimum_master_nodes属性。
该属性定义的是为了形成一个集群，有主节点资格并互相连接的节点的最小数目。
线程池的配置可以使用集群的更新API来更新，如下所示：curl -XPUT 'localhost:9200/_cluster/settings' -d 
curl -X PUT localhost:9200/_snapshot/backup
预热查询跟普通查询没什么区别，只是它存储在Elasticsearch一个特殊的名为_warmer的索引中。
index.search.slowlog: TRACE, index_search_slow_log_file 日志文件由logging.yml配置文件中的index_search_slow_log_file节点指定



http://news.oneapm.com/dangdang-oneapm/   电商搜索引擎的架构设计和性能优化
https://yq.aliyun.com/articles/4266?utm_source=tuicool&utm_medium=referral   OpenSearch：轻松构建大数据搜索服务

http://ylw6006.blog.51cto.com/470441/1722905  packetbeat
packetbeat -e -d "*"    https://www.elastic.co/guide/en/beats/packetbeat/1.1/enable-packetbeat-debugging.html
http://www.tuicool.com/articles/ZR7vIfu
topbeat -e    https://www.elastic.co/guide/en/beats/topbeat/1.1/enable-topbeat-debugging.html
http://www.tuicool.com/articles/VFrE7nY
http://www.ttlsa.com/elk/migration-logtash-forwarder-to-filebeat/

http://blog.zhenchuan.me/set-up-elk-elasticsearch/
http://kibana.logstash.es/content/elasticsearch/performance/curator.html
为了更加方便的做清除数据，合并 segment，备份恢复等管理任务，Elasticsearch 在提供相关 API 的同时，另外准备了一个命令行工具，叫 curator 。curator 是 Python 程序，可以直接通过 pypi 库安装：
wget --no-check-certificate https://bootstrap.pypa.io/get-pip.py
python get-pip.py
pip install elasticsearch-curator


HBase的Relication机制，其实和Mysql的同步机制很像，HBase的每个Region Server都会有WAL Log，当Put/Delete时，都会先写入到WAL Log里。然后后台有线程会把WAL Log随机发给Slave的Region Server。而Slave的Region Server会在zookeeper上记录自己同步到的位置。
http://blog.csdn.net/hengyunabc/article/details/41146115

类型（Type）是索引内部的一个逻辑划分，在一个索引内部可以定义多个类型（Type），类型将一个索引在逻辑上划分为多个集合，每个类型包含多个属性（字段）。ElasticSearch中类型，与HBase中列簇（Column Family）的概念很相似。
一个索引是很多文档的集合，将一个索引进行分割，分成多个片段（一个索引的子集），每一个片段称为一个分片（Shard），这样划分可以很好地管理索引，跨节点存储，为分布式存储于搜索提供了便利。副本（Replica）是为了保证一个分片（Shard）的可用性，冗余复制存储，当一个分片对应的数据无法读取时，可以读取其副本，正常提供搜索服务。
http://shiyanjun.cn/archives/1371.html   ElasticSearch-2.0.0集群安装配置与API使用实践


ES 是一个 P2P 类型(使用 gossip 协议)的分布式系统，除了集群状态管理以外，其他所有的请求都可以发送到集群内任意一台节点上，这个节点可以自己找到需要转发给哪些节点，并且直接跟这些节点通信。
只配置 cluster.name 的集群，其实就是采用了默认的自动发现协议，即组播(multicast)方式。节点会在本机所有网卡接口上，使用组播地址 224.2.2.4 ，以 54328 端口建立组播组发送 clustername 信息。
只有在同一个交换机下的节点，能自动发现，跨交换机的节点，是无法收到组播信息的。
Elasticsearch 2.0 开始，为安全考虑，默认不分发 multicast 功能。依然希望使用 multicast 自动发现的用户，需要单独安装:
bin/plugin install discovery-multicast
除了组播方式，ES 还支持单播(unicast)方式。配置里提供几台节点的地址，ES 将其视作 gossip router 角色，借以完成集群的发现。
ElastAlert 是 Yelp 公司开源的一套用 Python2.6 写的报警框架。属于后来 Elastic.co 公司出品的 Watcher 同类产品
为了更加方便的做清除数据，合并 segment，备份恢复等管理任务，Elasticsearch 在提供相关 API 的同时，另外准备了一个命令行工具，叫 curator 。curator 是 Python 程序，可以直接通过 pypi 库安装：
pip install elasticsearch-curator
curl -X GET 127.0.0.1:9200/_cluster/health?pretty

http://elasticsearch.cn/article/17
用 Logstash 接收 Kafka 里的业务日志再写入 Elasticsearch 已经成为一个常见的选择。但是大多数人随后就会碰到一个问题：logstash-input-kafka 的性能上不去！这个问题，主要是由于 Logstash 用 JRuby 实现
从 logstash-1.5.1 版开始，新发布了一个 logstash-input-heartbeat 插件，实现了一个最基本的队列堵塞状态监控。
Logstash 是一个运行在 JVM 上的软件，也就意味着 JMX 这种对 JVM 的通用监控方式对 Logstash 也是一样有效果的。甚至 logstash 自己也有插件 logstash-input-jmx 来读取远程 JMX 数据。
注意，zabbix-server 本身并不直接对 JMX 发起请求，而是单独有一个 Java Gateway 作为中间代理层角色。zabbix-server 的 java poller 连接 zabbix-java-gateway，由 zabbix-java-gateway 去获取远程 JMX 信息。
https://www.elastic.co/blog/logstash-kafka-intro
bin/logstash -e "input { stdin {} } output { kafka { topic_id => 'logstash_logs' } }"
bin/logtash -e "input { kafka { topic_id => 'logstash_logs' } } output { elasticsearch { protocol => http } }"


http://www.ashishpaliwal.com/blog/2015/04/geospatial-indexing-with-elasticsearch/  位置搜索
http://blog.zhenchuan.me/deep-into-elasticsearch/   深入理解 elasticsearch
http://shokunin.co/blog/2013/06/24/elasticsearch.html
http://blog.csdn.net/july_2/article/details/24702243
plugin -install lukas-vlcek/bigdesk
http://localhost:9200/_plugin/bigdesk/ 
plugin -install royrusso/elasticsearch-HQ

https://www.elastic.co/guide/en/sense/current/installing.html#installing
kibana plugin --install elastic/sense
http://localhost:5601/app/sense

2.0可以免费使用一个集群 https://www.elastic.co/downloads/marvel
plugin install license
plugin install marvel-agent
http://localhost:5601/app/marvel
http://www.vpsee.com/2014/05/install-and-play-with-elasticsearch/
plugin -i elasticsearch/marvel/latest

https://github.com/lmenezes/elasticsearch-kopf

plugin -install mobz/elasticsearch-head
http://localhost:9200/_plugin/head/


plugin -install karmi/elasticsearch-paramedic
https://github.com/is00hcw/elasticsearch-paramedic

plugin install elasticsearch/elasticsearch-analysis-smartcn/2.7.0
https://github.com/elastic/elasticsearch-analysis-smartcn

http://www.shenjuanli.com/2014/03/03/logstashelasticsearchkibana%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E6%9C%AA%E5%AE%8C%EF%BC%89/
http://segmentfault.com/a/1190000002904818

http://blog.csdn.net/liuzhenfeng/article/details/39404435  Elasticsearch安装中文分词插件ik

http://segmentfault.com/a/1190000002972420   kibana使用的lucene查询语法

http://blog.csdn.net/u014201191/article/details/46508311   

pip install elasticsearch


http://www.vpsee.com/2015/03/a-modern-monitoring-system-built-with-grafana-collected-influxdb/  使用 Grafana＋collectd＋InfluxDB 打造现代监控系统

http://www.zihou.me/html/2014/01/17/9061.html  elasticsearch.yml配置说明
http://zhaoyanblog.com/archives/319.html  elasticsearch三个重要的优化   配置index.refresh_interval参数，默认是1s
此处可以根据机器硬件配置情况作出适当的调整，一般情况下，此处的内存分配大小为机器物理内存的一半，同时将 ES_MIN_MEM 与 ES_MAX_MEM 配置成相同的值
由于ES集群一般都是在内部网络环境中，且节点之间相互通信使用的是 TCP 9300端口，节点与客户端通信则是通过 TCP 9200端口。因此检查 iptalbes 以及SElinux 中是否开启，以及确定这些端口是否被绑定安全策略等等。
可以在最后的上线之前可以再做一次最后的测试，在测试之前，先修改Elasticsearch 中的配置文件，即是elasticsearch.yml 中的 cluster.name 参数的名称，避免加入了线上集群中。并利用 curl -X GET localhost:9200  来测试新版本的 Elasticsearch 进程是否正常。　　
系统不能限制打开的文件描述符小于32 000个。在Linux上，一般在/etc/security/limits.conf中修改，当前的值可以用ulimit命令来查看。如果达到极限，Elasticsearch将无法创建新的文件，所以合并会失败，索引会失败，新的索引无法创建。

http://my.oschina.net/galenz/blog/422189   Elasticsearch 分片交互过程分析
http://www.cnblogs.com/xing901022/p/4967796.html  Elasticsearch 数据搜索篇 【入门级干货】

备份恢复
在浏览器中运行http://ipaddress:9200/_flush，这样确保索引数据能保存到硬盘中。
http://keenwon.com/1393.html
http://m.blog.csdn.net/blog/huwei2003/41577017
http://segmentfault.com/q/1010000002406786

同义词
http://blog.csdn.net/yusewuhen/article/details/50685685   Elasticsearch 自带一个名为 synonym 的同义词 filter
http://www.ifunit.com/29/elasticsearch%E9%85%8D%E7%BD%AE%E5%90%8C%E4%B9%89%E8%AF%8D
http://www.cnblogs.com/buzzlight/p/elasticsearch_analysis.html  
全文搜索引擎会用某种算法对要建索引的文档进行分析， 从文档中提取出若干Token(词元)， 这些算法称为Tokenizer(分词器)， 这些Token会被进一步处理， 比如转成小写等， 这些处理算法被称为Token Filter(词元处理器), 被处理后的结果被称为Term(词)， 文档中包含了几个这样的Term被称为Frequency(词频)。 引擎会建立Term和原文档的Inverted Index(倒排索引)， 这样就能根据Term很快到找到源文档了。 文本被Tokenizer处理前可能要做一些预处理， 比如去掉里面的HTML标记， 这些处理的算法被称为Character Filter(字符过滤器)， 这整个的分析算法被称为Analyzer(分析器)。

http://www.infoq.com/cn/news/2015/02/apache-lucene5-release
http://www.cnblogs.com/ibook360/archive/2012/12/29/2839094.html
http://itindex.net/detail/49374-lucene-4.8.0-%E5%8F%98%E5%8C%96
提供了针对第一次搜索结果集合的重打分（权重调整）API；相当于对搜索结果的二次自定义排序。 
AnalyzingInfixSuggester 类提供了支持NRT的自动建议功能。 


分析的工作由分析器完成，它由一个分词器（tokenizer）和零个或多个标记过滤器（token filter）组成，也可以有零个或多个字符映射器（character mapper）。
Lucene中的分词器把文本分割成多个标记，基本就是词加上一些额外信息，比如该词在原始文本中的位置和长度。默认情况下，Apache Lucene使用TF/IDF（term frequency/inverse document frequency，词频/逆向文档频率）评分机制
收到查询请求的节点会把查询转发给保存了属于给定索引的分片的所有节点，并要求与查询匹配的文档的最少信息（默认情况下是标识符和得分）。这个过程称为发散阶段（scatter phase）。收到这些信息后，该聚合节点（收到客户端请求的节点）对结果排序，并发送第2个请求来获取结果列表所需的文档（除了标识符和
得分以外的所有信息）。这个阶段称为收集阶段（gather phase）。这个阶段执行完毕后，结果返回到客户端。

index_options：该属性定义了信息列表（postings list）的索引选项（2.2.4节将详细讨论）。可能的值是docs（仅对文档编号建立索引）， freqs（对文档编号和词频建立索引），positions（对文档编号、词频和它们的位置建立索引）， offsets（对文档编号、词频、它们的位置和偏移量建立索引）。对于经分析的字段，此属性的默认值是positions，对于未经分析的字段，默认值为docs。
例如，对cars和car这两个单词，词干提取器（stemmer，词干提取算法的一种实现）产生一个词干car。
2012年发布Apache Lucene 4.0后，该全文检索库的所有用户便可以修改默认的基于TF/IDF的算法。 Lucene 4.0还附加了相似度模型（similarity model），允许在文档中使用不同的评分公式  BM25相似度模型
Okapi BM25模型：这种相似度模型基于概率模型，概率模型估算根据指定查询找到指定文档的概率。


http://my.oschina.net/galenz/blog/333070  Zabbix的安装与部署

wget http://mirror.bit.edu.cn/apache/flume/1.6.0/apache-flume-1.6.0-bin.tar.gz
wget http://download.elastic.co/kibana/kibana/kibana-4.2.0-linux-x64.tar.gz
wget https://download.elastic.co/logstash/logstash/logstash-2.0.0.tar.gz
wget https://download.elasticsearch.org/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/2.0.0/elasticsearch-2.0.0.tar.gz
./plugin install lukas-vlcek/bigdesk
config/kibana.yml in an editor Set the elasticsearch.url 
http://115.28.225.5:5601/app/kibana
http://demo.elastic.co/packetbeat/#/discover   官方测试的页面
http://segmentfault.com/a/1190000002972420     kibana使用的lucene查询语法
https://www.elastic.co/guide/en/logstash/current/output-plugins.html
http://udn.yyuap.com/doc/logstash-best-practice-cn/input/index.html
?只是插入新增的日志

http://blog.csdn.net/sunflower_cao/article/details/39929931?utm_source=tuicool&utm_medium=referral
http://ju.outofmemory.cn/entry/119397
http://flume.apache.org/FlumeUserGuide.html#elasticsearchsink
The elasticsearch and lucene-core jars required for your environment must be placed in the lib directory of the Apache Flume installation.
flume1.6 还不支持 es2.0
